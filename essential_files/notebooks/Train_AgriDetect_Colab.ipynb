{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üå± Plant Disease Classification - Training on Google Colab\n",
    "\n",
    "This notebook trains a ResNet-50 model on your high-accuracy AgriDetect dataset (99.7%).\n",
    "\n",
    "**Estimated Time**: 30-60 minutes with free GPU\n",
    "\n",
    "**Steps**:\n",
    "1. Upload your dataset zip file\n",
    "2. Install dependencies\n",
    "3. Train the model\n",
    "4. Download the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU detected! Go to Runtime > Change runtime type > Select GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets accelerate scikit-learn pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Upload Dataset\n",
    "\n",
    "Upload `AgriDetect.v1i.folder-2.zip` using the file upload button below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "print(\"üì§ Upload your AgriDetect.v1i.folder-2.zip file:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Extract the zip file\n",
    "zip_filename = list(uploaded.keys())[0]\n",
    "print(f\"\\nüì¶ Extracting {zip_filename}...\")\n",
    "\n",
    "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "    zip_ref.extractall('AgriDetect_new_model')\n",
    "\n",
    "print(\"‚úÖ Dataset extracted!\")\n",
    "print(f\"\\nDataset structure:\")\n",
    "!ls -la AgriDetect_new_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoImageProcessor,\n",
    "    AutoModelForImageClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Plant Disease Classification - Colab Training\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Configuration\n",
    "DATASET_DIR = \"AgriDetect_new_model\"\n",
    "MODEL_NAME = \"microsoft/resnet-50\"\n",
    "OUTPUT_DIR = \"./plant-disease-model-v2\"\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 32  # Larger batch size for GPU\n",
    "LEARNING_RATE = 2e-5\n",
    "\n",
    "print(f\"\\nüìä Configuration:\")\n",
    "print(f\"   Dataset: {DATASET_DIR} (99.7% accuracy)\")\n",
    "print(f\"   Base Model: {MODEL_NAME}\")\n",
    "print(f\"   Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"   Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   Learning Rate: {LEARNING_RATE}\")\n",
    "\n",
    "# Load dataset\n",
    "print(f\"\\nüì• Loading dataset...\")\n",
    "dataset = load_dataset(\n",
    "    \"imagefolder\",\n",
    "    data_dir=DATASET_DIR,\n",
    "    drop_labels=False\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Dataset loaded!\")\n",
    "print(f\"   Train: {len(dataset['train'])} images\")\n",
    "print(f\"   Validation: {len(dataset['validation'])} images\")\n",
    "print(f\"   Test: {len(dataset['test'])} images\")\n",
    "\n",
    "# Get labels\n",
    "labels = dataset[\"train\"].features[\"label\"].names\n",
    "num_labels = len(labels)\n",
    "print(f\"\\nüè∑Ô∏è  Classes ({num_labels}):\")\n",
    "for i, label in enumerate(labels):\n",
    "    print(f\"   {i}: {label}\")\n",
    "\n",
    "# Load image processor\n",
    "print(f\"\\nüîß Loading image processor...\")\n",
    "image_processor = AutoImageProcessor.from_pretrained(MODEL_NAME)\n",
    "print(f\"‚úÖ Image processor loaded!\")\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_images(examples):\n",
    "    \"\"\"Preprocess images for the model\"\"\"\n",
    "    images = [img.convert(\"RGB\") for img in examples[\"image\"]]\n",
    "    inputs = image_processor(images, return_tensors=\"pt\")\n",
    "    inputs = {k: v.squeeze() if v.ndim > 1 and v.shape[0] == 1 else v for k, v in inputs.items()}\n",
    "    inputs[\"labels\"] = examples[\"label\"]\n",
    "    return inputs\n",
    "\n",
    "# Apply preprocessing\n",
    "print(f\"\\nüîÑ Preprocessing images...\")\n",
    "dataset = dataset.map(\n",
    "    preprocess_images,\n",
    "    batched=True,\n",
    "    batch_size=32,\n",
    "    remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "print(f\"‚úÖ Preprocessing complete!\")\n",
    "\n",
    "# Load model\n",
    "print(f\"\\nü§ñ Loading model...\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=num_labels,\n",
    "    id2label={i: label for i, label in enumerate(labels)},\n",
    "    label2id={label: i for i, label in enumerate(labels)},\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "print(f\"‚úÖ Model loaded!\")\n",
    "\n",
    "# Metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Compute accuracy, precision, recall, F1\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='weighted'\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "# Training arguments\n",
    "print(f\"\\n‚öôÔ∏è  Setting up training...\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=f\"{OUTPUT_DIR}/logs\",\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Trainer ready!\")\n",
    "\n",
    "# Check device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"\\nüíª Device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è  No GPU detected!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üöÄ STARTING TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nThis will take 30-60 minutes with GPU...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train_results = trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ TRAINING COMPLETE!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "print(\"\\nüìä Evaluating on validation set...\")\n",
    "val_metrics = trainer.evaluate()\n",
    "print(f\"\\nValidation Results:\")\n",
    "print(f\"   Accuracy:  {val_metrics['eval_accuracy']:.4f} ({val_metrics['eval_accuracy']*100:.2f}%)\")\n",
    "print(f\"   Precision: {val_metrics['eval_precision']:.4f}\")\n",
    "print(f\"   Recall:    {val_metrics['eval_recall']:.4f}\")\n",
    "print(f\"   F1 Score:  {val_metrics['eval_f1']:.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\nüìä Evaluating on test set...\")\n",
    "test_metrics = trainer.evaluate(dataset[\"test\"])\n",
    "print(f\"\\nTest Results:\")\n",
    "print(f\"   Accuracy:  {test_metrics['eval_accuracy']:.4f} ({test_metrics['eval_accuracy']*100:.2f}%)\")\n",
    "print(f\"   Precision: {test_metrics['eval_precision']:.4f}\")\n",
    "print(f\"   Recall:    {test_metrics['eval_recall']:.4f}\")\n",
    "print(f\"   F1 Score:  {test_metrics['eval_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "print(f\"\\nüíæ Saving model to {OUTPUT_DIR}...\")\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "image_processor.save_pretrained(OUTPUT_DIR)\n",
    "print(f\"‚úÖ Model saved!\")\n",
    "\n",
    "# Save metrics to file\n",
    "with open(f\"{OUTPUT_DIR}/metrics.txt\", \"w\") as f:\n",
    "    f.write(\"Plant Disease Classification - Training Results\\n\")\n",
    "    f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "    f.write(f\"Dataset: {DATASET_DIR}\\n\")\n",
    "    f.write(f\"Model: {MODEL_NAME}\\n\")\n",
    "    f.write(f\"Epochs: {NUM_EPOCHS}\\n\\n\")\n",
    "    f.write(\"Validation Metrics:\\n\")\n",
    "    f.write(f\"  Accuracy:  {val_metrics['eval_accuracy']:.4f} ({val_metrics['eval_accuracy']*100:.2f}%)\\n\")\n",
    "    f.write(f\"  Precision: {val_metrics['eval_precision']:.4f}\\n\")\n",
    "    f.write(f\"  Recall:    {val_metrics['eval_recall']:.4f}\\n\")\n",
    "    f.write(f\"  F1 Score:  {val_metrics['eval_f1']:.4f}\\n\\n\")\n",
    "    f.write(\"Test Metrics:\\n\")\n",
    "    f.write(f\"  Accuracy:  {test_metrics['eval_accuracy']:.4f} ({test_metrics['eval_accuracy']*100:.2f}%)\\n\")\n",
    "    f.write(f\"  Precision: {test_metrics['eval_precision']:.4f}\\n\")\n",
    "    f.write(f\"  Recall:    {test_metrics['eval_recall']:.4f}\\n\")\n",
    "    f.write(f\"  F1 Score:  {test_metrics['eval_f1']:.4f}\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéâ ALL DONE!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nYour trained model is in: {OUTPUT_DIR}\")\n",
    "print(f\"Metrics saved to: {OUTPUT_DIR}/metrics.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Download the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip the model folder for download\n",
    "import shutil\n",
    "\n",
    "print(\"üì¶ Creating zip file for download...\")\n",
    "shutil.make_archive('plant-disease-model-v2', 'zip', OUTPUT_DIR)\n",
    "print(\"‚úÖ Zip file created!\")\n",
    "\n",
    "# Download the model\n",
    "print(\"\\n‚¨áÔ∏è Downloading model...\")\n",
    "files.download('plant-disease-model-v2.zip')\n",
    "print(\"‚úÖ Download started! Check your browser downloads.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Test a Prediction (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load a test image\n",
    "test_image_path = dataset[\"test\"][0][\"image\"]  # Get first test image\n",
    "image = Image.open(test_image_path).convert(\"RGB\")\n",
    "\n",
    "# Preprocess\n",
    "inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "# Get prediction\n",
    "predicted_class_idx = logits.argmax(-1).item()\n",
    "confidence = probabilities[0][predicted_class_idx].item()\n",
    "predicted_label = model.config.id2label[predicted_class_idx]\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.title(f\"Prediction: {predicted_label}\\nConfidence: {confidence*100:.2f}%\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüéØ Prediction: {predicted_label}\")\n",
    "print(f\"üìä Confidence: {confidence*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Training Complete!\n",
    "\n",
    "Your model has been trained and is ready to use!\n",
    "\n",
    "**Next Steps:**\n",
    "1. Download the model zip file (already started above)\n",
    "2. Extract it on your local machine\n",
    "3. Run the Streamlit app: `streamlit run streamlit_app_local.py`\n",
    "4. Test with your own plant images!\n",
    "\n",
    "**Expected Results:**\n",
    "- Accuracy: ~99.7%\n",
    "- Much better than the previous 60-76%!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
